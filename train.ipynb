{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import  Dataset, DataLoader\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SongDataset(Dataset):    \n",
    "\n",
    "    def __init__(self, songs, max_song):\n",
    "        \n",
    "        self.songs = songs\n",
    "        self.max_song = max_song\n",
    "        self.vector = np.zeros(max_song, dtype=np.float32)\n",
    "        \n",
    "    def get_vector(self, vec):\n",
    "        cop_vector = copy.deepcopy(self.vector)\n",
    "        if vec:\n",
    "            cop_vector[vec] = 1            \n",
    "        return cop_vector    \n",
    "\n",
    "        \n",
    "    def denosing(self, x):\n",
    "        if len(x)<2:\n",
    "            return x\n",
    "        tr, te = train_test_split(x, test_size=0.2)\n",
    "        return tr\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.songs[idx]        \n",
    "        d_x = self.denosing(x)\n",
    "        d_x = self.get_vector(d_x)\n",
    "        x = self.get_vector(x)\n",
    "        return d_x, x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./dataset/meta.pkl', 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "    max_song = len(meta['idx_song'])\n",
    "\n",
    "with open('./dataset/train.json', encoding='UTF-8') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs = [x[\"songs\"]  for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707989"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://cs230.stanford.edu/files_winter_2018/projects/6937581.pdf\n",
    "# https://openreview.net/pdf?id=SkNQeiRpb\n",
    "# n, 128, 256, 256, dp(0.65), 256, 128, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse_loss_with_nans(output, target):\n",
    "\n",
    "    # Missing data are nan's\n",
    "    # mask = torch.isnan(target)\n",
    "\n",
    "    # Missing data are 0's\n",
    "    mask = target == 0\n",
    "\n",
    "    out = (output[~mask]-target[~mask])**2\n",
    "    loss = out.mean()\n",
    "\n",
    "    return torch.sqrt(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = SongDataset(songs, max_song)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n -> 128 -> 256 -> 256 -> || -> 256 -> \n",
    "class AE(nn.Module):\n",
    "    def __init__(self, max_song):\n",
    "        \n",
    "        super(AE, self).__init__()        \n",
    "        self.encoder = nn.Sequential(\n",
    "                    nn.Linear(max_song, 128), \n",
    "                    nn.SELU(),\n",
    "                    nn.Linear(128, 256),\n",
    "                    nn.SELU(),\n",
    "                    nn.Linear(256, 256),\n",
    "                    nn.SELU()\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.7)\n",
    "        self.decoder = nn.Sequential(\n",
    "                    nn.Linear(256, 256),\n",
    "                    nn.SELU(),                    \n",
    "                    nn.Linear(256, 128),\n",
    "                    nn.SELU(),                    \n",
    "                    nn.Linear(128, max_song), \n",
    "                    nn.SELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.decoder(x)        \n",
    "        \n",
    "        return x\n",
    "model = AE(max_song)\n",
    "criterion = mse_loss_with_nans\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 362490368 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cfb669fc8ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\com\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\com\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 362490368 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "model.train()\n",
    "total_loss = list()\n",
    "path = \"model_{}.pth\"\n",
    "for epoch in range(epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    running_loss = 0 \n",
    "    for batch_id, (dx, x) in enumerate(tqdm_notebook(dataloader)): #model.train()\n",
    "        optimizer.zero_grad()        \n",
    "        output = model(dx)\n",
    "        \n",
    "        loss = criterion(output, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()         \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_id % 30 == 0:\n",
    "            print(\"epoch {} batch id {} run_loss {:.4f} loss {:.4f}\".format(epoch+1, batch_id+1, running_loss/(batch_id+1),loss.item() ))\n",
    "            \n",
    "    total_loss.append(running_loss/(batch_id+1))\n",
    "    print(total_loss)\n",
    "    w_path = path.format(str(epoch))\n",
    "    torch.save(model.state_dict(), w_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKQghbuISApSuIuIpCCFu4hICvr/zh52T3AfXEQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17b2ac36898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#year과 pop은 미리 세팅됨\n",
    "# Make a line plot: year on the x-axis, pop on the y-axis\n",
    "plt.plot(total_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1656,  0.1124,  0.0337,  ...,  0.8059,  0.3827, -0.0185],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(131270)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(output[0]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9891, 0.5362, 0.9547,  ..., 1.0000, 0.8872, 0.0445],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24409,  26083,  44603,  49047,  49921,  59003,  66214,  67697,\n",
       "        87668,  95181, 109574, 116250, 116573, 118060, 119795, 121362,\n",
       "       147466, 155233, 178124, 180708, 183949, 193610, 194117, 209120,\n",
       "       216192, 219044, 231659, 241481, 246029, 253571, 258919, 285157,\n",
       "       290769, 291080, 304964, 321321, 330238, 330553, 336933, 340679,\n",
       "       342836, 348200, 355939, 356211, 362228, 372094, 373910, 375227,\n",
       "       377785, 382542, 385234, 390770, 393654, 395416, 408870, 418519,\n",
       "       438424, 440217, 442352, 465778, 472583, 485481, 491539, 504520,\n",
       "       522825, 526161, 528599, 545007, 570171, 578240, 582137, 584775,\n",
       "       586306, 590012, 600475, 604182, 606607, 608563, 610933, 617277,\n",
       "       625650, 625875, 629738, 638130, 639531, 645489, 650764, 651499,\n",
       "       656391, 657022, 669701, 670156, 674505, 686809, 700444, 701557,\n",
       "       707564])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(len(x[0]))[x[0]>0]\n",
    "a\n",
    "# y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 26083,  44603,  66214,  87668,  95181, 116250, 116573, 119795,\n",
       "       121362, 147466, 155233, 178124, 180708, 183949, 193610, 194117,\n",
       "       216192, 219044, 231659, 241481, 246029, 253571, 258919, 290769,\n",
       "       291080, 304964, 321321, 330238, 336933, 340679, 342836, 355939,\n",
       "       356211, 362228, 373910, 382542, 385234, 390770, 393654, 395416,\n",
       "       408870, 418519, 438424, 440217, 442352, 465778, 472583, 485481,\n",
       "       491539, 522825, 526161, 528599, 545007, 570171, 578240, 582137,\n",
       "       584775, 586306, 606607, 608563, 610933, 617277, 625650, 629738,\n",
       "       638130, 639531, 645489, 651499, 656391, 657022, 669701, 670156,\n",
       "       674505, 686809, 700444, 701557, 707564])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(dx[0]))[dx[0]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24409,  26083,  44603,  49047,  49921,  59003,  66214,  67697,\n",
       "        87668,  95181, 109574, 116250, 116573, 118060, 119795, 121362,\n",
       "       147466, 155233, 178124, 180708, 183949, 193610, 194117, 209120,\n",
       "       216192, 219044, 231659, 241481, 246029, 253571, 258919, 285157,\n",
       "       290769, 291080, 304964, 321321, 330238, 330553, 336933, 340679,\n",
       "       342836, 348200, 355939, 356211, 362228, 372094, 373910, 375227,\n",
       "       377785, 382542, 385234, 390770, 393654, 395416, 408870, 418519,\n",
       "       438424, 440217, 442352, 465778, 472583, 485481, 491539, 504520,\n",
       "       522825, 526161, 528599, 545007, 570171, 578240, 582137, 584775,\n",
       "       586306, 590012, 600475, 604182, 606607, 608563, 610933, 617277,\n",
       "       625650, 625875, 629738, 638130, 639531, 645489, 650764, 651499,\n",
       "       656391, 657022, 669701, 670156, 674505, 686809, 700444, 701557,\n",
       "       707564])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.arange(len(x[0]))[x[0]>0]\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9989, 0.9734, 0.9883, 1.0041, 0.9984, 0.9938, 0.9261, 1.0370, 1.0375,\n",
       "        1.0848, 0.9601, 0.9917, 1.0259, 0.9806, 1.0084, 0.8422, 0.7190, 0.9086,\n",
       "        1.0424, 0.7072, 1.0020, 1.0485, 1.0163, 0.9784, 0.9217, 0.7594, 1.0091,\n",
       "        0.9789, 1.0274, 1.0168, 1.0186, 0.9595, 1.0157, 0.9761, 1.0449, 1.1034,\n",
       "        0.9751, 0.9663, 0.9651, 0.9696, 0.9361, 1.0330, 1.0471, 1.0555, 0.9818,\n",
       "        1.1405, 0.9849, 0.9537, 0.6701, 0.8301, 0.9741, 0.9297, 0.9484, 1.0126,\n",
       "        0.9874, 0.9863, 0.9769, 0.9835, 0.9959, 1.0085, 1.0536, 0.9525, 0.9900,\n",
       "        0.9912, 0.9709, 1.0245, 0.9543, 0.9528, 0.9482, 0.9554, 0.9042, 0.9140,\n",
       "        1.0114, 0.9912, 0.9008, 1.0192, 0.9766, 0.9125, 1.0154, 0.9694, 1.0152,\n",
       "        1.0227, 0.9649, 0.9949, 0.8577, 0.9965, 1.0723, 1.0934, 0.7656, 1.0328,\n",
       "        0.9908, 0.7995, 1.0298, 0.9836, 0.7657, 1.0039, 0.9773],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][aa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([570637,  55884, 142955, 525178, 135288, 496515,  48367, 549597,\n",
       "       413106, 525045, 705018, 591516, 145363, 139750, 476061, 200744,\n",
       "         9036, 194767, 154333, 570914, 457770, 455217,  48220, 138834,\n",
       "       650532, 691608, 209998, 488067,  89104, 603537, 110562, 415922,\n",
       "       701093, 665795, 152148, 306736,  10162, 404908, 416916,  37261,\n",
       "       287950, 571588,  43886,  38678, 281197, 515536, 587715, 124106,\n",
       "       439364,  29505,   3039, 226893, 359950,  88887, 666927, 373700,\n",
       "       460198, 291884, 571969, 569928, 421179,  48358, 268478, 673739,\n",
       "       690288, 641471, 391928, 154772, 483083, 428538, 306195, 700393,\n",
       "       382342, 420269, 511249, 585922, 545575, 603199, 416662, 509317,\n",
       "       358088, 160810, 219017, 528997, 126804, 558227, 542497, 121040,\n",
       "       411548, 202618, 112738, 196588,  44004, 460752, 100237, 681262,\n",
       "       593593, 154362, 416801, 383586], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = output[0].data.numpy().argsort()[-100:]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7839, 0.9263, 0.6435, 0.8657, 0.9375, 1.1569, 0.9021, 1.0635, 0.7660,\n",
       "        1.0110, 1.0078, 1.1363, 0.9434, 0.8942, 0.9051, 0.9163, 0.6797],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][aa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3440679, 1.3441871, 1.3442128, 1.3443112, 1.3447115, 1.3449464,\n",
       "       1.3449816, 1.3450669, 1.3459816, 1.3461945, 1.3463833, 1.3482533,\n",
       "       1.3486217, 1.3487881, 1.3496361, 1.350858 , 1.3514051, 1.352024 ,\n",
       "       1.353617 , 1.3536423, 1.3541024, 1.3550597, 1.3551944, 1.3552893,\n",
       "       1.3565935, 1.3571932, 1.3573041, 1.3575879, 1.359416 , 1.359509 ,\n",
       "       1.3595399, 1.3601441, 1.3603214, 1.3609442, 1.361938 , 1.3626397,\n",
       "       1.3636484, 1.3637273, 1.3660142, 1.3662732, 1.3683466, 1.3698038,\n",
       "       1.3703653, 1.371133 , 1.3713459, 1.3715507, 1.3716218, 1.3734533,\n",
       "       1.3754936, 1.3755518, 1.3780223, 1.3797876, 1.3825054, 1.3831165,\n",
       "       1.3833661, 1.3843997, 1.3845721, 1.3857245, 1.3880674, 1.3887419,\n",
       "       1.3891057, 1.393857 , 1.3946155, 1.3947212, 1.3965513, 1.3979863,\n",
       "       1.3992945, 1.3994298, 1.4001682, 1.4002291, 1.400767 , 1.4012548,\n",
       "       1.4024173, 1.4029381, 1.4037236, 1.4039928, 1.4044383, 1.4045256,\n",
       "       1.404688 , 1.4057602, 1.4063166, 1.4072641, 1.4163641, 1.4169823,\n",
       "       1.4182907, 1.419734 , 1.4200761, 1.423029 , 1.4269862, 1.4415404,\n",
       "       1.4419385, 1.4429379, 1.4477113, 1.4728655, 1.4831645, 1.4860952,\n",
       "       1.5111022, 1.5130454, 1.5263574, 1.5351677], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].data.numpy()[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111004"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[0][output[0]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 0.9586, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        0.9308, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][x[0]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {
    "3c126124aa5741fd96ca58c7e7893639": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
